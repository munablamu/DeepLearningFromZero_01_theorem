{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第8章 ディープラーニング\n",
    "## 8.1 ネットワークをより深く\n",
    "### 8.1.1 よりディープなネットワークへ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.2699192546944906\n",
      "=== epoch:1, train acc:0.086, test acc:0.072 ===\n",
      "train loss:2.317309375478337\n",
      "train loss:2.3290199456969805\n",
      "train loss:2.2961689621576484\n",
      "train loss:2.2951679187821656\n",
      "train loss:2.281256277634077\n",
      "train loss:2.2805043754958274\n",
      "train loss:2.3050848161713393\n",
      "train loss:2.2772856247349686\n",
      "train loss:2.271474148988028\n",
      "train loss:2.2854497513932412\n",
      "train loss:2.286863316070153\n",
      "train loss:2.265192984824177\n",
      "train loss:2.2657729593041647\n",
      "train loss:2.268157366904048\n",
      "train loss:2.259603387808489\n",
      "train loss:2.2262465571585994\n",
      "train loss:2.238646287970617\n",
      "train loss:2.210681656734015\n",
      "train loss:2.2761088926145963\n",
      "train loss:2.201311727008226\n",
      "train loss:2.2183910062247914\n",
      "train loss:2.189620479850799\n",
      "train loss:2.217714757274003\n",
      "train loss:2.186066529147864\n",
      "train loss:2.105629938932232\n",
      "train loss:2.111537424313854\n",
      "train loss:2.100464211586951\n",
      "train loss:2.0649073268888056\n",
      "train loss:2.202194377728766\n",
      "train loss:1.9920330235592414\n",
      "train loss:2.000069825538807\n",
      "train loss:2.1978291713030513\n",
      "train loss:2.1226821326628156\n",
      "train loss:2.04011976073035\n",
      "train loss:1.9442020270697327\n",
      "train loss:1.919658207007989\n",
      "train loss:1.9053868743486317\n",
      "train loss:1.9529705871658394\n",
      "train loss:1.9452391847725996\n",
      "train loss:1.835931648841789\n",
      "train loss:1.934656218174633\n",
      "train loss:1.97840526754273\n",
      "train loss:1.9331004123561548\n",
      "train loss:1.827662762062099\n",
      "train loss:1.943491834464636\n",
      "train loss:1.8637962860049055\n",
      "train loss:1.8951322016319454\n",
      "train loss:1.9066481772999302\n",
      "train loss:1.893510342453184\n",
      "train loss:2.020006174762373\n",
      "train loss:1.9635872656259983\n",
      "train loss:1.8470909921964918\n",
      "train loss:1.9133465806278847\n",
      "train loss:1.8853330964168264\n",
      "train loss:1.862709986884295\n",
      "train loss:1.840919126753163\n",
      "train loss:1.850191424364302\n",
      "train loss:1.8035610966492046\n",
      "train loss:1.91121564102718\n",
      "train loss:1.8187993460675915\n",
      "train loss:1.7969917846827659\n",
      "train loss:1.8432682421515407\n",
      "train loss:1.7972918504282316\n",
      "train loss:1.7752976933892293\n",
      "train loss:1.8643647494417186\n",
      "train loss:1.8481743846217498\n",
      "train loss:1.8494067836581458\n",
      "train loss:1.817797067509524\n",
      "train loss:1.825529330469312\n",
      "train loss:1.7827636609952242\n",
      "train loss:1.6316108461430971\n",
      "train loss:1.7081117144820126\n",
      "train loss:1.6832400920637685\n",
      "train loss:1.8820010811542038\n",
      "train loss:1.8261914388218192\n",
      "train loss:1.7508075740711058\n",
      "train loss:1.812758915743902\n",
      "train loss:1.7433344577317529\n",
      "train loss:1.8133307313093932\n",
      "train loss:1.5777095678613475\n",
      "train loss:1.6210962313170276\n",
      "train loss:1.4894184081274164\n",
      "train loss:1.6653396246159498\n",
      "train loss:1.775357293535713\n",
      "train loss:1.5953373851960044\n",
      "train loss:1.7229968209994297\n",
      "train loss:1.7078066314137723\n",
      "train loss:1.5741070778751969\n",
      "train loss:1.8308028608443392\n",
      "train loss:1.6591935907736264\n",
      "train loss:1.4115204368322432\n",
      "train loss:1.6890702541141727\n",
      "train loss:1.6526992088884247\n",
      "train loss:1.6156174993136672\n",
      "train loss:1.6596308108273343\n",
      "train loss:1.6670001989808292\n",
      "train loss:1.7840747761534848\n",
      "train loss:1.5749229363107904\n",
      "train loss:1.5774744509230112\n",
      "train loss:1.428486325451037\n",
      "train loss:1.4534696938718528\n",
      "train loss:1.7308225515827331\n",
      "train loss:1.8377377629957328\n",
      "train loss:1.535516002571778\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/py_workspace/DeepLearningFromZero/01_theorem/ch08/train_deepnet.py:16\u001b[0m\n\u001b[1;32m     11\u001b[0m network \u001b[39m=\u001b[39m DeepConvNet()\n\u001b[1;32m     12\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(network, x_train, t_train, x_test, t_test,\n\u001b[1;32m     13\u001b[0m                   epochs\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m, mini_batch_size\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m,\n\u001b[1;32m     14\u001b[0m                   optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mAdam\u001b[39m\u001b[39m'\u001b[39m, optimizer_param\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mlr\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m0.001\u001b[39m},\n\u001b[1;32m     15\u001b[0m                   evaluate_sample_num_per_epoch\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n\u001b[1;32m     18\u001b[0m \u001b[39m# パラメータの保存\u001b[39;00m\n\u001b[1;32m     19\u001b[0m network\u001b[39m.\u001b[39msave_params(\u001b[39m\"\u001b[39m\u001b[39mdeep_convnet_params.pkl\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/py_workspace/DeepLearningFromZero/01_theorem/ch08/../common/trainer.py:71\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m     70\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_iter):\n\u001b[0;32m---> 71\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_step()\n\u001b[1;32m     73\u001b[0m     test_acc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnetwork\u001b[39m.\u001b[39maccuracy(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx_test, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mt_test)\n\u001b[1;32m     75\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose:\n",
      "File \u001b[0;32m~/py_workspace/DeepLearningFromZero/01_theorem/ch08/../common/trainer.py:47\u001b[0m, in \u001b[0;36mTrainer.train_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     44\u001b[0m grads \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnetwork\u001b[39m.\u001b[39mgradient(x_batch, t_batch)\n\u001b[1;32m     45\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnetwork\u001b[39m.\u001b[39mparams, grads)\n\u001b[0;32m---> 47\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnetwork\u001b[39m.\u001b[39;49mloss(x_batch, t_batch)\n\u001b[1;32m     48\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_loss_list\u001b[39m.\u001b[39mappend(loss)\n\u001b[1;32m     49\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose: \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mtrain loss:\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(loss))\n",
      "File \u001b[0;32m~/py_workspace/DeepLearningFromZero/01_theorem/ch08/deep_convnet.py:82\u001b[0m, in \u001b[0;36mDeepConvNet.loss\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mloss\u001b[39m(\u001b[39mself\u001b[39m, x, t):\n\u001b[0;32m---> 82\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(x, train_flg\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     83\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlast_layer\u001b[39m.\u001b[39mforward(y, t)\n",
      "File \u001b[0;32m~/py_workspace/DeepLearningFromZero/01_theorem/ch08/deep_convnet.py:78\u001b[0m, in \u001b[0;36mDeepConvNet.predict\u001b[0;34m(self, x, train_flg)\u001b[0m\n\u001b[1;32m     76\u001b[0m         x \u001b[39m=\u001b[39m layer\u001b[39m.\u001b[39mforward(x, train_flg)\n\u001b[1;32m     77\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m         x \u001b[39m=\u001b[39m layer\u001b[39m.\u001b[39;49mforward(x)\n\u001b[1;32m     79\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/py_workspace/DeepLearningFromZero/01_theorem/ch08/../common/layers.py:261\u001b[0m, in \u001b[0;36mPooling.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    258\u001b[0m out_h \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m (H \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool_h) \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride)\n\u001b[1;32m    259\u001b[0m out_w \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m (W \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool_w) \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride)\n\u001b[0;32m--> 261\u001b[0m col \u001b[39m=\u001b[39m im2col(x, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpool_h, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpool_w, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpad)\n\u001b[1;32m    262\u001b[0m col \u001b[39m=\u001b[39m col\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool_h\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool_w)\n\u001b[1;32m    264\u001b[0m arg_max \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(col, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/py_workspace/DeepLearningFromZero/01_theorem/ch08/../common/util.py:65\u001b[0m, in \u001b[0;36mim2col\u001b[0;34m(input_data, filter_h, filter_w, stride, pad)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(filter_w):\n\u001b[1;32m     64\u001b[0m         x_max \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m stride\u001b[39m*\u001b[39mout_w\n\u001b[0;32m---> 65\u001b[0m         col[:, :, y, x, :, :] \u001b[39m=\u001b[39m img[:, :, y:y_max:stride, x:x_max:stride]\n\u001b[1;32m     67\u001b[0m col \u001b[39m=\u001b[39m col\u001b[39m.\u001b[39mtranspose(\u001b[39m0\u001b[39m, \u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m)\u001b[39m.\u001b[39mreshape(N\u001b[39m*\u001b[39mout_h\u001b[39m*\u001b[39mout_w, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     68\u001b[0m \u001b[39mreturn\u001b[39;00m col\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%run train_deepnet.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
